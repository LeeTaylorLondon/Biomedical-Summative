C:\Users\lees_\Scripts\python.exe C:\Users\lees_\PycharmProjects\Biomedical-Summative\Scripts\machine_learning_vgg16.py
2022-12-15 09:19:16.311218: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
>>> Created model(s)
>>> Train-testing model
(5121, 208, 176, 3) (5121, 4)
Epoch 1/3
2561/2561 [==============================] - 1454s 567ms/step - loss: 0.4617 - accuracy: 0.4845
Epoch 2/3
2561/2561 [==============================] - 1428s 558ms/step - loss: 0.4548 - accuracy: 0.4878
Epoch 3/3
2561/2561 [==============================] - 1442s 563ms/step - loss: 0.4534 - accuracy: 0.4931

TIME TAKEN: 4326.390141487122
40/40 [==============================] - 48s 1s/step - loss: 0.4376 - accuracy: 0.5004
TESTING ACC.: 0.5003909468650818

>>> Train-testing model
(5121, 208, 176, 3) (5121, 4)
Epoch 1/3
Traceback (most recent call last):
  File "C:\Users\lees_\PycharmProjects\Biomedical-Summative\Scripts\machine_learning_vgg16.py", line 66, in <module>
    traintest_model(model, x_train_, y_train_, x_test_, y_test_)
  File "C:\Users\lees_\PycharmProjects\Biomedical-Summative\Scripts\machine_learning_vgg16.py", line 36, in traintest_model
    history = model.fit(x_train, y_train,
  File "C:\Users\lees_\lib\site-packages\keras\utils\traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "C:\Users\lees_\AppData\Local\Temp\__autograph_generated_fileqxkjz2ee.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
tensorflow.python.autograph.pyct.error_utils.MultilineMessageKeyError: in user code:

    File "C:\Users\lees_\lib\site-packages\keras\engine\training.py", line 1249, in train_function  *
        return step_function(self, iterator)
    File "C:\Users\lees_\lib\site-packages\keras\engine\training.py", line 1233, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "C:\Users\lees_\lib\site-packages\keras\engine\training.py", line 1222, in run_step  **
        outputs = model.train_step(data)
    File "C:\Users\lees_\lib\site-packages\keras\engine\training.py", line 1027, in train_step
        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File "C:\Users\lees_\lib\site-packages\keras\optimizers\optimizer_experimental\optimizer.py", line 527, in minimize
        self.apply_gradients(grads_and_vars)
    File "C:\Users\lees_\lib\site-packages\keras\optimizers\optimizer_experimental\optimizer.py", line 1140, in apply_gradients
        return super().apply_gradients(grads_and_vars, name=name)
    File "C:\Users\lees_\lib\site-packages\keras\optimizers\optimizer_experimental\optimizer.py", line 634, in apply_gradients
        iteration = self._internal_apply_gradients(grads_and_vars)
    File "C:\Users\lees_\lib\site-packages\keras\optimizers\optimizer_experimental\optimizer.py", line 1166, in _internal_apply_gradients
        return tf.__internal__.distribute.interim.maybe_merge_call(
    File "C:\Users\lees_\lib\site-packages\keras\optimizers\optimizer_experimental\optimizer.py", line 1216, in _distributed_apply_gradients_fn
        distribution.extended.update(
    File "C:\Users\lees_\lib\site-packages\keras\optimizers\optimizer_experimental\optimizer.py", line 1213, in apply_grad_to_update_var  **
        return self._update_step(grad, var)
    File "C:\Users\lees_\lib\site-packages\keras\optimizers\optimizer_experimental\optimizer.py", line 216, in _update_step
        raise KeyError(

    KeyError: 'The optimizer cannot recognize variable block1_conv1/kernel:0. This usually means you are trying to call the optimizer to update different parts of the model separately. Please call `optimizer.build(variables)` with the full list of trainable variables before the training loop or use legacy optimizer `tf.keras.optimizers.legacy.{self.__class__.__name__}.'


Process finished with exit code 1
